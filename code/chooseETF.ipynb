{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEARSONBOUND = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicFileName=\"basic_data.csv\"\n",
    "basicDF=pd.read_csv('../data/'+basicFileName)\n",
    "basicDF.drop_duplicates(inplace=True)\n",
    "basicDF['Symbol'].to_csv('../data/'+'ETFs.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3963\n",
      "2136\n",
      "1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3158792/2128863428.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  firstDF.dropna(inplace=True,subset=['Category'])\n",
      "/tmp/ipykernel_3158792/2128863428.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  firstDF.dropna(inplace=True,subset=['Index'])\n",
      "/tmp/ipykernel_3158792/2128863428.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  firstDF.dropna(inplace=True,subset=['Assets'])\n"
     ]
    }
   ],
   "source": [
    "def firstSelect(df):\n",
    "    \n",
    "    #Inception记录股票上市时间\n",
    "    firstDF=df[['Symbol','Fund Name','Assets','Category','Index','Inception','Volume']]\n",
    "    print(len(firstDF))\n",
    "    firstDF.dropna(inplace=True,subset=['Category'])\n",
    "    firstDF.dropna(inplace=True,subset=['Index'])\n",
    "    firstDF.dropna(inplace=True,subset=['Assets'])\n",
    "    print(len(firstDF))\n",
    "\n",
    "    category_counts=firstDF['Category'].value_counts()\n",
    "    firstDF=firstDF[firstDF['Category'].isin(category_counts[category_counts>5].index)]\n",
    "    firstDF = firstDF.loc[firstDF.groupby('Index')['Assets'].idxmax()]\n",
    "\n",
    "    # 重置索引（可选）\n",
    "    firstDF = firstDF.reset_index(drop=True)\n",
    "\n",
    "    print(len(firstDF))\n",
    "\n",
    "    firstDF[['Index','Symbol']].to_csv(\"./111.csv\")\n",
    "    return firstDF\n",
    "    \n",
    "\n",
    "firstDF=firstSelect(basicDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Net Assets by Category:\n",
      "\n",
      "38                Large Blend\n",
      "39               Large Growth\n",
      "40                Large Value\n",
      "18        Foreign Large Blend\n",
      "66                 Technology\n",
      "               ...           \n",
      "64        Tactical Allocation\n",
      "53        Nontraditional Bond\n",
      "60            Single Currency\n",
      "67    Trading--Inverse Equity\n",
      "14              Equity Hedged\n",
      "Name: Category, Length: 73, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#计算每类股票的资产总和\n",
    "def category_assets(df):\n",
    "    require_colums= [\"Category\",\"Assets\"]\n",
    "    for col in require_colums:\n",
    "        if col not in firstDF.columns:\n",
    "            print(\"Error: Missing column \"+col)\n",
    "            return\n",
    "\n",
    "    df[\"Assets\"]=pd.to_numeric(df[\"Assets\"],errors='coerce')\n",
    "    categorys=df.groupby(\"Category\")[\"Assets\"].sum().reset_index()\n",
    "    categorys=categorys.sort_values(\"Assets\",ascending=False)\n",
    "    \n",
    "    print(\"\\nNet Assets by Category:\\n\")\n",
    "    \n",
    "    \n",
    "    categorys.to_csv(\"../data/category_assets.csv\")\n",
    "    return categorys\n",
    "\n",
    "categorys=category_assets(firstDF)\n",
    "categorys.to_csv(\"../data/categorys.csv\")\n",
    "print(categorys[\"Category\"])\n",
    "# print(categorys[categorys[\"Category\"]==\"Large Blend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Assets:  7760177616282.0\n",
      "\n",
      "Net Assets by Category:\n",
      "\n",
      "1258\n"
     ]
    }
   ],
   "source": [
    "#Setp3:删除流动性和资产小于 val 的基金\n",
    "\n",
    "\n",
    "\n",
    "def filter_fund(df,categorys):\n",
    "    #决定使用哪种方式保留ETF\n",
    "    #0表示绝对数额，1表示百分比\n",
    "    method=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    filtered_df = df.copy()\n",
    "    require_colums= [\"Category\",\"Assets\",\"Volume\"]\n",
    "    for col in require_colums:\n",
    "        if col not in firstDF.columns:\n",
    "            print(\"Error: Missing column \"+col)\n",
    "            return\n",
    "\n",
    "    totAssets=categorys[\"Assets\"].sum()\n",
    "    print(\"Total Assets: \",totAssets)\n",
    "        \n",
    "    cateVal={\"-1\":-1}\n",
    "    for etf in df[\"Category\"]:\n",
    "        cateVal[etf]=categorys[categorys[\"Category\"]==etf][\"Assets\"].values[0]\n",
    "    \n",
    "    df[\"calval\"]=df[\"Category\"].map(cateVal)\n",
    "    \n",
    "    # 保留Assets大于0.1%总资产的基金和大于5%该类资产的基金\n",
    "    if(method==0):\n",
    "        \n",
    "        filtered_df = df[\n",
    "            (df['Assets'] > 0.001 * totAssets) |\n",
    "            (df['Assets'] > df['Category'].map(lambda ca: 0.05 * cateVal.get(ca, 0)))\n",
    "        ]\n",
    "    \n",
    "    if(method==1):\n",
    "        # 第一步：计算全局的 Assets 后 10% 阈值\n",
    "        global_threshold = filtered_df['Assets'].quantile(0.10)\n",
    "\n",
    "        # 第二步：对每个 Category 计算 Assets 后 25% 的阈值\n",
    "        category_thresholds = filtered_df.groupby('Category')['Assets'].transform(lambda x: x.quantile(0.25))\n",
    "\n",
    "        # 第三步：过滤掉满足任一条件的股票\n",
    "        filtered_df = filtered_df[~((filtered_df['Assets'] <= category_thresholds) | (df['Assets'] <= global_threshold))]\n",
    "\n",
    "    \n",
    "    filtered_df = filtered_df[~filtered_df['Category'].str.contains('Leverage', na=False)]\n",
    "    filtered_df.to_csv(\"../data/filter_fund.csv\")\n",
    "    \n",
    "    filtered_df[\"Symbol\"].to_csv(\"../data/ETF1s.csv\",index=False)\n",
    "    return filtered_df\n",
    "\n",
    "secondDF=filter_fund(firstDF,categorys)\n",
    "categorys=category_assets(firstDF)\n",
    "print(len(secondDF))\n",
    "secondDF[\"Symbol\"].to_csv(\"./ETF2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year     Alpha      Beta  Correlation\n",
      "0   2010  0.000182  1.018034         True\n",
      "1   2011  0.000050  0.973697         True\n",
      "2   2012  0.000018  1.099745         True\n",
      "3   2013  0.000139  0.971461         True\n",
      "4   2014  0.000126  1.133949         True\n",
      "5   2015  0.000327  1.092120         True\n",
      "6   2016 -0.000199  1.124886         True\n",
      "7   2017  0.000188  1.214837         True\n",
      "8   2018  0.000229  1.268274         True\n",
      "9   2019 -0.000012  1.225012         True\n",
      "10  2020  0.000905  0.996076         True\n",
      "11  2021 -0.000256  1.228431         True\n",
      "12  2022 -0.000500  1.282122         True\n",
      "13  2023  0.000615  1.251975         True\n",
      "14  2024 -0.000228  1.349062         True\n",
      "15  2025 -0.000972  1.308638         True\n",
      "1258\n"
     ]
    }
   ],
   "source": [
    "# linear_regression(SPY,ETF)\n",
    "# find alpha and beta and 皮尔逊相关系数\n",
    "\n",
    "def linear_regression_time(basicDf1,basicDf2,st,et):\n",
    "    st=pd.to_datetime(st).date()\n",
    "    et=pd.to_datetime(et).date()\n",
    "    \n",
    "    # basicDf1[\"Date\"]=pd.to_datetime(basicDf1[\"date\"]).dt.date\n",
    "    # basicDf2[\"Date\"]=pd.to_datetime(basicDf2[\"date\"]).dt.date\n",
    "    basicDf1=basicDf1[(basicDf1[\"Date\"]>=st) & (basicDf1[\"Date\"]<=et)]\n",
    "    basicDf2=basicDf2[(basicDf2[\"Date\"]>=st) & (basicDf2[\"Date\"]<=et)]\n",
    "    # common_dates=set(basicDf1['Date']).intersection(set(basicDf2['Date']))\n",
    "    # common_dates=sorted(list(common_dates))\n",
    "    \n",
    "    # df1=basicDf1[basicDf1['Date'].isin(common_dates)]\n",
    "    # df2=basicDf2[basicDf2['Date'].isin(common_dates)]\n",
    "    if(len(basicDf1)<=5 or len(basicDf2)<=5):\n",
    "        return np.nan,np.nan,False\n",
    "    \n",
    "    basicDf1.reset_index(drop=True,inplace=True)\n",
    "    basicDf2.reset_index(drop=True,inplace=True)\n",
    "    df1=basicDf1[['Date','close']]\n",
    "    df2=basicDf2[['Date','close']]\n",
    "    \n",
    "    df=pd.merge(df1[['Date','close']],df2[['Date','close']],on='Date',suffixes=('_1','_2'))\n",
    "    \n",
    "    \n",
    "    df['return1']=df1['close'].pct_change()\n",
    "    df['return2']=df2['close'].pct_change()\n",
    "    \n",
    "    \n",
    "    df=df.dropna()\n",
    "    x = sm.add_constant(df['return1'])\n",
    "    y = df['return2']\n",
    "\n",
    "    model = sm.OLS(y, x).fit()\n",
    "    \n",
    "    alpha = model.params['const']\n",
    "    beta = model.params['return1']\n",
    "    \n",
    "    correlation=np.corrcoef(df['return1'],df['return2'])[0,1]\n",
    "    \n",
    "    \n",
    "    # print(\"Alpha:\", alpha)\n",
    "    # print(\"Beta:\", beta)\n",
    "    # # 绘制 SPY 和 ETF 收益率的散点图和回归线\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.scatter(df['return1'], df['return2'], label='Data Points', alpha=0.6)\n",
    "    # plt.plot(df['return1'], alpha + beta * df['return1'], color='red', label='Regression Line')\n",
    "\n",
    "    # # 添加图表标题和标签\n",
    "    # plt.title('ETF Returns vs SPY Returns (Alpha and Beta)', fontsize=16)\n",
    "    # plt.xlabel('SPY Returns', fontsize=12)\n",
    "    # plt.ylabel('ETF Returns', fontsize=12)\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    return alpha,beta,(abs(correlation)>PEARSONBOUND)\n",
    "\n",
    "\n",
    "\n",
    "def linear_regression(basicDf1,basicDf2):\n",
    "    basicDf1[\"Date\"]=pd.to_datetime(basicDf1[\"date\"]).dt.date\n",
    "    basicDf2[\"Date\"]=pd.to_datetime(basicDf2[\"date\"]).dt.date\n",
    "    common_dates=set(basicDf1['Date']).intersection(set(basicDf2['Date']))\n",
    "    common_dates=sorted(list(common_dates))\n",
    "    \n",
    "    df1=basicDf1[basicDf1['Date'].isin(common_dates)]\n",
    "    df2=basicDf2[basicDf2['Date'].isin(common_dates)]\n",
    "    \n",
    "    \n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    df2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    \n",
    "    alphas=[]\n",
    "    betas=[]\n",
    "    correlations=[]\n",
    "    for year in range(2010,2026):\n",
    "        st=str(year)+'-01-01'\n",
    "        et=str(year)+'-12-31'\n",
    "        a,b,c=linear_regression_time(df1,df2,st,et)\n",
    "        alphas.append(a)\n",
    "        betas.append(b)\n",
    "        correlations.append(c)\n",
    "    \n",
    "    alphaBeta=pd.DataFrame({'Year':range(2010,2026),'Alpha':alphas,'Beta':betas,'Correlation':correlations})\n",
    "    \n",
    "    # print(\"Alpha:\", alpha)\n",
    "    # print(\"Beta:\", beta)\n",
    "    # # 绘制 SPY 和 ETF 收益率的散点图和回归线\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.scatter(df['return1'], df['return2'], label='Data Points', alpha=0.6)\n",
    "    # plt.plot(df['return1'], alpha + beta * df['return1'], color='red', label='Regression Line')\n",
    "\n",
    "    # # 添加图表标题和标签\n",
    "    # plt.title('ETF Returns vs SPY Returns (Alpha and Beta)', fontsize=16)\n",
    "    # plt.xlabel('SPY Returns', fontsize=12)\n",
    "    # plt.ylabel('ETF Returns', fontsize=12)\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    return alphaBeta\n",
    "\n",
    "\n",
    "\n",
    "dfSPY=pd.read_csv(\"../data/daily_data/SPY_daily.csv\")\n",
    "dfQQQ=pd.read_csv(\"../data/daily_data/QQQ_daily.csv\")\n",
    "# a,b,c=linear_regression(dfSPY,dfVOO)\n",
    "alphaBeta=linear_regression(dfSPY,dfQQQ)\n",
    "print(alphaBeta)\n",
    "print(len(secondDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alpha_beta_val(alphaBeta):\n",
    "    namda=0.95 #权重\n",
    "    score=0\n",
    "    for year in range(2010,2026):\n",
    "        i=year-2010\n",
    "        if(np.isnan(alphaBeta.loc[i,'Alpha'])):\n",
    "            continue\n",
    "            \n",
    "        score+=np.power(namda,2025-year)*(alphaBeta.loc[i,'Alpha']+np.max(0,0.5-alphaBeta.loc[i,'Beta'])+0.1*np.max(0,alphaBeta.loc[i,'Correlation']-PEARSONBOUND))\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     ThirdDF\u001b[38;5;241m=\u001b[39mdf[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(goodETFs)]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ThirdDF\n\u001b[0;32m---> 26\u001b[0m ThirdDF\u001b[38;5;241m=\u001b[39m\u001b[43mchooseGoodAlpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecondDF\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ThirdDF))\n\u001b[1;32m     28\u001b[0m ThirdDF[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/ETF3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[40], line 20\u001b[0m, in \u001b[0;36mchooseGoodAlpha\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(etf)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# print(len(dfETF))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# print(SPYETF.head())\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# print(dfETF.head())\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     alphaBeta\u001b[38;5;241m=\u001b[39mlinear_regression(SPYETF,dfETF)\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcalculate_alpha_beta_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphaBeta\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.0001\u001b[39m:\n\u001b[1;32m     21\u001b[0m         goodETFs\u001b[38;5;241m.\u001b[39mappend(etf)\n\u001b[1;32m     23\u001b[0m ThirdDF\u001b[38;5;241m=\u001b[39mdf[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(goodETFs)]\n",
      "Cell \u001b[0;32mIn[39], line 9\u001b[0m, in \u001b[0;36mcalculate_alpha_beta_val\u001b[0;34m(alphaBeta)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(np\u001b[38;5;241m.\u001b[39misnan(alphaBeta\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlpha\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     score\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mpower(namda,\u001b[38;5;241m2025\u001b[39m\u001b[38;5;241m-\u001b[39myear)\u001b[38;5;241m*\u001b[39m(alphaBeta\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlpha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43malphaBeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBeta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m0\u001b[39m,alphaBeta\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrelation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39mPEARSONBOUND))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2820\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2705\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2706\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "def chooseGoodAlpha(df):\n",
    "    goodETFs=[]\n",
    "    SPYETF=pd.read_csv(\"../data/daily_data/SPY_daily.csv\")\n",
    "    for etf in df[\"Symbol\"]:\n",
    "        try :\n",
    "            dfETF=pd.read_csv(\"../data/daily_data/\"+etf+\"_daily.csv\")\n",
    "        except Exception as e:\n",
    "            print(\"Error: \",etf)\n",
    "            print(e)\n",
    "            continue\n",
    "        if len(dfETF)<10:\n",
    "            print(\"Empty: \",etf)\n",
    "            continue\n",
    "        # print(etf)\n",
    "        # print(len(dfETF))\n",
    "        # print(SPYETF.head())\n",
    "        # print(dfETF.head())\n",
    "        alphaBeta=linear_regression(SPYETF,dfETF)\n",
    "        \n",
    "        if calculate_alpha_beta_val(alphaBeta)>-0.0001:\n",
    "            goodETFs.append(etf)\n",
    "        \n",
    "    ThirdDF=df[df[\"Symbol\"].isin(goodETFs)]\n",
    "    return ThirdDF\n",
    "\n",
    "ThirdDF=chooseGoodAlpha(secondDF)\n",
    "print(len(ThirdDF))\n",
    "ThirdDF[\"Symbol\"].to_csv(\"../data/ETF3.csv\",index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
